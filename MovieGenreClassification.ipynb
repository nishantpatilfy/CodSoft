{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcede55e-925e-44b3-b529-7e80825bf7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dbe389e-f4c5-4b85-8b06-1fa9558cdc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success with encoding: utf-8\n",
      "Loaded 54214 movies\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = read_data_safely('train_data.txt')\n",
    "print(f\"Loaded {len(df)} movies\")\n",
    "\n",
    "# Clean text\n",
    "def clean(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df['text'] = df['plot'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70123b15-c07f-4b3e-b3da-d97744743f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_safely(path):\n",
    "    for encoding in ['utf-8', 'latin-1', 'windows-1252']:\n",
    "        try:\n",
    "            with open(path, 'r', encoding=encoding) as f:\n",
    "                lines = f.readlines()\n",
    "            print(f\"Success with encoding: {encoding}\")\n",
    "            break\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    else:\n",
    "        raise ValueError(\"Could not read the file with any encoding\")\n",
    "\n",
    "    movies = []\n",
    "    for line in lines:\n",
    "        parts = line.strip().split(' ::: ')\n",
    "        if len(parts) == 4:\n",
    "            _, title, genre, plot = parts\n",
    "            movies.append({'title': title, 'genre': genre.lower(), 'plot': plot})\n",
    "    return pd.DataFrame(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6d31a9f-fa69-4108-910a-f3816fb32c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression + TF-IDF (this is the best model for this task)...\n",
      "\n",
      "======================================================================\n",
      "LOGISTIC REGRESSION ACCURACY: 0.5191 → 51.91%\n",
      "======================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      action     0.3374    0.5247    0.4107       263\n",
      "       adult     0.4531    0.7373    0.5613       118\n",
      "   adventure     0.2245    0.3548    0.2750       155\n",
      "   animation     0.1812    0.2500    0.2101       100\n",
      "   biography     0.0290    0.0377    0.0328        53\n",
      "      comedy     0.6003    0.5181    0.5562      1490\n",
      "       crime     0.1264    0.2277    0.1625       101\n",
      " documentary     0.7895    0.6415    0.7078      2619\n",
      "       drama     0.7025    0.4414    0.5422      2723\n",
      "      family     0.1901    0.3185    0.2381       157\n",
      "     fantasy     0.1235    0.1538    0.1370        65\n",
      "   game-show     0.7714    0.6923    0.7297        39\n",
      "     history     0.1226    0.2653    0.1677        49\n",
      "      horror     0.5859    0.6961    0.6363       441\n",
      "       music     0.4098    0.7466    0.5291       146\n",
      "     musical     0.1286    0.1636    0.1440        55\n",
      "     mystery     0.1319    0.1875    0.1548        64\n",
      "        news     0.1951    0.2222    0.2078        36\n",
      "  reality-tv     0.3137    0.5424    0.3975       177\n",
      "     romance     0.1580    0.4552    0.2346       134\n",
      "      sci-fi     0.3133    0.6047    0.4127       129\n",
      "       short     0.4407    0.4355    0.4381      1015\n",
      "       sport     0.4244    0.8488    0.5659        86\n",
      "   talk-show     0.2847    0.5000    0.3628        78\n",
      "    thriller     0.2625    0.3805    0.3107       318\n",
      "         war     0.2182    0.4615    0.2963        26\n",
      "     western     0.7511    0.8641    0.8036       206\n",
      "\n",
      "    accuracy                         0.5191     10843\n",
      "   macro avg     0.3433    0.4545    0.3787     10843\n",
      "weighted avg     0.5871    0.5191    0.5376     10843\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#encode labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['genre'])\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training Logistic Regression + TF-IDF (this is the best model for this task)...\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = make_pipeline(\n",
    "    TfidfVectorizer(\n",
    "        max_features=15000,\n",
    "        ngram_range=(1, 3),          # unigrams + bigrams + trigrams\n",
    "        stop_words='english',\n",
    "        sublinear_tf=True,\n",
    "        lowercase=True\n",
    "    ),\n",
    "    LogisticRegression(\n",
    "        C=2.0,\n",
    "        class_weight='balanced',     # helps with drama/comedy imbalance\n",
    "        max_iter=1000,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "#training\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"LOGISTIC REGRESSION ACCURACY: {acc:.4f} → {acc*100:.2f}%\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7f0725-ed98-48e5-9fef-f6a8c4f44c55",
   "metadata": {},
   "source": [
    "#### Current model is only really reliable for horror and documentary. For everything else, it’s barely better than guessing or always saying “drama”.\n",
    "#### 51.91% with classic Logistic Regression/TF-IDF on 27 genres is actually completely normal, it’s just that plot text alone is not enough to reliably distinguish 27 fine-grained genres.\n",
    "#### Macro-average F1 = 0.379 → if all genres were equally important, the model would be terrible.\n",
    "#### Weighted-average F1 = 0.537 → pulled up by the few genres that work well (horror, documentary, comedy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7123d31b-aeab-49d7-a546-1c1f3f3a84d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
