{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4687c20-09ef-4d4c-a4ec-828cc4f46dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from xgboost import XGBClassifier  # pip install xgboost if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "600c7a20-0e02-4d67-8086-0885e4265892",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Churn_Modelling.csv')\n",
    "\n",
    "df = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "#fatures and target\n",
    "X = df.drop('Exited', axis=1)\n",
    "y = df['Exited']\n",
    "\n",
    "#categorical and numerical features\n",
    "categorical_features = ['Geography', 'Gender']\n",
    "numerical_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feabbe42-6da7-4246-98ba-1853fea0f2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
    "    ])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18154f40-4326-4b02-8451-2c20a76cf9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to train and evaluate\n",
    "def train_evaluate(model, name):\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', model)])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    print(f\"\\n=== {name} Results ===\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d10bfbd-1021-44ac-8143-79bceb3c3b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression Results ===\n",
      "Accuracy: 0.714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.72      0.80      1593\n",
      "           1       0.39      0.70      0.50       407\n",
      "\n",
      "    accuracy                           0.71      2000\n",
      "   macro avg       0.65      0.71      0.65      2000\n",
      "weighted avg       0.80      0.71      0.74      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1143  450]\n",
      " [ 122  285]]\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "lr = LogisticRegression(random_state=42, class_weight='balanced')  # Balanced for imbalance\n",
    "train_evaluate(lr, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb67d1b-4c9a-475e-b1e6-4b88caf214ea",
   "metadata": {},
   "source": [
    "#### Highest recall (70%) → catches most churners\n",
    "#### But 450 false positives and only 39% precision → predicts churn too often\n",
    "#### Will annoy many loyal customers → bad customer experience\n",
    "#### Only use this if missing a churner is extremely costly and you’re okay with over-alerting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c217c069-8cbe-4072-aa44-52f13d74ab91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest Results ===\n",
      "Accuracy: 0.861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92      1593\n",
      "           1       0.78      0.44      0.56       407\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.83      0.70      0.74      2000\n",
      "weighted avg       0.85      0.86      0.85      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1543   50]\n",
      " [ 228  179]]\n"
     ]
    }
   ],
   "source": [
    "#random forest\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=100, class_weight='balanced')\n",
    "train_evaluate(rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b7d9b2-2068-4176-8acf-1f6999da03e4",
   "metadata": {},
   "source": [
    "#### Highest accuracy (86.1%) and best precision (78%)\n",
    "#### Only 50 false positives → only 50 loyal customers wrongly flagged as \"will churn\"\n",
    "#### This is critical in real life: you don’t want to spam loyal customers with retention offers\n",
    "#### Catches 179 out of 407 actual churners (44%) — acceptable trade-off for low noise\n",
    "\n",
    "#### Best choice if the goal is: “Target high-risk customers with confidence and avoid annoying good customers.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c566ab2-4ecb-42d1-a52c-ce3c78470fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== XGBoost Results ===\n",
      "Accuracy: 0.8225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89      1593\n",
      "           1       0.56      0.62      0.59       407\n",
      "\n",
      "    accuracy                           0.82      2000\n",
      "   macro avg       0.73      0.75      0.74      2000\n",
      "weighted avg       0.83      0.82      0.83      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1393  200]\n",
      " [ 155  252]]\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "xgb = XGBClassifier(random_state=42, scale_pos_weight=(y_train.value_counts()[0] / y_train.value_counts()[1]))  # Handle imbalance\n",
    "train_evaluate(xgb, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c96ca8-9431-44ba-ac4d-381faffe840a",
   "metadata": {},
   "source": [
    "#### Highest F1-score on churn class (0.59) → best balance between precision and recall\n",
    "#### Catches 252 out of 407 churners (62%) — highest recall among the three\n",
    "#### Still reasonable precision (only 200 false positives)\n",
    "#### Best choice if the goal is: “Catch as many churners as possible, even if it means some false alarms.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6004092a-82b2-4f28-92e3-a7916d3d432f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
